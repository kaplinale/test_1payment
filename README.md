                                             
1. Описание требований проекта test_1payment
  Есть некоторый веб сервис, который требуется развернуть в инфраструктуре AWS. Для сервиса необходимо обеспечить безопасность, отказоустойчивость, масштабирование и мониторинг.

2. Описание требований сервиса
  Сервис должен быть реализован на основе веб-сервера nginx. В сервисе должна быть реализована "ручка"(endpoint) '/health' для проверки состояния сервиса(200/OK) а также endpoint '/' возвращающий требуемые запросом данные. Логи сервиса должны быть вынесены в отдельную директорию и подвергнуты ротации.

3. Реализация(архитектура) облачной инфраструктуры
   Облачная инфраструтктура выполнена в парадигме IAC средствами terraform и провадера aws к нему. Схема доступа к сервису реализована следующим образом:
   [Internet] -> [route53] -> [alb/elb] -> [EC2 instances]
   Доступ к сервису в целях сетевой безопасности ограничен портами 80/tcp и 22/tcp для dev-окружения и 443/tcp для prod-окружения. Доступ в инфраструктуру к серверам организован непосредственно через IPSEC.

4. Прикладная часть(сервис).
   Прикладная часть организована в виде веб-сервера nginx. Деплой прикладной части организован посредством ansible роли. Релизованы endpoint-ты описанные в требованиях.

5. Структура проекта в виде IAC

infra | - корневая директория проекта
      | - terraform - скрипты на HCL для развертывания облачной части
      | - ansible   - плейбуки и роли для развертывания прикладной части
      | - scripts   - скрипты для проверки

6. Развертывание

6.1 Облачная часть
    Подготавливаем нужное количество инстансов в файле ec2_instances.tf по аналогии, как указано там в примерах. В alb.tf прописываем инстансы для балансировки, как в примерах в коде.
    в папке terraform выполняем последовательно:
    terraform init # скачивание провайдера
    terraform validate # проверка кода
    terraform plan -out=plan.out # отображение измений в облачной инфраструктуре.
    terraform apply --auto-approve plan.out # применение изменений

6.2 Прикладная часть.
    Получаем ip инстансов EC2 через консоль AWS. Заполняем файл hosts.ini в директории ansible по шаблону, который в нем указан. Выставляем параметр nginx_log_path в asnible/roles/webservice/default/main.yml, указывая полный путь к папке с логами сервиса.
    в папке ansible выполняем:
    ansible-playbook -u techuser -i hosts.ini ansible/roles/main.yml -b
    Требования к пользователю techuser, который должен быть "прошит" в AMI инстансов:
     - для данного пользователя предварительно должна быть сгенерирована пара private/public ключей.
     - пользователь должен состоять в группе wheels для RHEL-подобных систем, либо в группе sudo для Debian-подобных.
     - для пользователя отключить проверку по паролям в /etc/sudoers

6.3 Проверка
    В папке scripts выполняем:
    ./check.sh ../ansible/hosts.ini
    В выводе должен быть ip -адрес ноды/инстанса сервиса и код ответа('Ok')

7. Отказоусточивость 
   Реализация отказоустойчивости выполнена на уровне оснастки ALB, которая проверяет ноды/инстансы по ендпойнту /heаlth и в случае превышения лимита неудачных проверок выводит ноду из балансировки.

8. Масштабирование
   Масштабирование(горизонтальное) реализуется путем добавления инстансов в ec2_instances.tf. Вертикальное - путем смены типа инстанса на более подходящий по параметрам(память/cpu и т.п.)

9. Безопасность
   Организована на уровне оснастки SG в AWS. При доступе на инстанс по ssh должен быть организован доступ по ключу.

10. Мониторинг
    Можно организовать путем связки prometheus/grafana с оповещениями через alert manager. Оповещения также можно высылать в почту, либо в канал TG.

11. Улучшения и оптимизация
    1. Циклическое добавление ec2 инстансов в группу балансировки для ALB, тем самым избавляя от необходимости каждый раз прописывать в alb.tf.
    2. Использовать модули terraform там, где это возможно.

12. Причины выбора инструментариев развертывания
    - гибкость
    - декларативность
    - скорость развертывания сервиса при наштатных/аварийных ситуацияю

